"""
Graph Validation - Weight tiling ë° shape ê²€ì¦
"""
from typing import Dict, List, Tuple
from .compute_node import ComputeGraph, ComputeNode
from ..hardware import PIMSimulator


class GraphValidator:
    """ì—°ì‚° ê·¸ë˜í”„ ê²€ì¦"""
    
    def __init__(self, graph: ComputeGraph, pim: PIMSimulator):
        self.graph = graph
        self.pim = pim
        self.errors = []
        self.warnings = []
    
    # ==================== Helper Functions ====================
    
    @staticmethod
    def _is_continuous_coverage(ranges: List[Tuple[int, int]], expected_start: int, expected_end: int) -> Tuple[bool, str]:
        """
        ë²”ìœ„ë“¤ì´ [expected_start, expected_end)ë¥¼ ì—°ì†ì ìœ¼ë¡œ ì™„ì „íˆ ì»¤ë²„í•˜ëŠ”ì§€ í™•ì¸
        
        Returns:
            (is_valid, error_message)
        """
        if not ranges:
            return False, "No ranges provided"
        
        # ë²”ìœ„ë“¤ì„ ì‹œì‘ ìœ„ì¹˜ë¡œ ì •ë ¬
        sorted_ranges = sorted(ranges, key=lambda x: x[0])
        
        # ì²« ë²”ìœ„ê°€ expected_startì—ì„œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
        if sorted_ranges[0][0] != expected_start:
            return False, f"First range starts at {sorted_ranges[0][0]}, expected {expected_start}"
        
        # ì—°ì†ì„± ë° ì™„ì „ì„± í™•ì¸
        current_end = sorted_ranges[0][1]
        
        for i in range(1, len(sorted_ranges)):
            start, end = sorted_ranges[i]
            
            # Gap í™•ì¸
            if start > current_end:
                return False, f"Gap found: [{current_end}, {start})"
            
            # Overlap í™•ì¸
            if start < current_end:
                return False, f"Overlap found: previous ends at {current_end}, next starts at {start}"
            
            current_end = end
        
        # ë§ˆì§€ë§‰ ë²”ìœ„ê°€ expected_endê¹Œì§€ ë„ë‹¬í•˜ëŠ”ì§€ í™•ì¸
        if current_end != expected_end:
            return False, f"Last range ends at {current_end}, expected {expected_end}"
        
        return True, ""
    
    @staticmethod
    def _has_overlap(ranges: List[Tuple[int, int]]) -> bool:
        """ë²”ìœ„ë“¤ì´ ì¤‘ë³µë˜ëŠ”ì§€ í™•ì¸"""
        sorted_ranges = sorted(ranges, key=lambda x: x[0])
        
        for i in range(len(sorted_ranges) - 1):
            if sorted_ranges[i][1] > sorted_ranges[i + 1][0]:
                return True
        
        return False
    
    @staticmethod
    def _calculate_conv_output_size(input_size: int, kernel_size: int, stride: int, padding: int) -> int:
        """Conv ì—°ì‚°ì˜ ì¶œë ¥ spatial size ê³„ì‚°"""
        return (input_size - kernel_size + 2 * padding) // stride + 1
    
    def validate(self) -> bool:
        """
        ì „ì²´ ê·¸ë˜í”„ ê²€ì¦
        
        Returns:
            ê²€ì¦ ì„±ê³µ ì—¬ë¶€
        """
        self.errors = []
        self.warnings = []
        
        # 1. Graph topology ê²€ì¦ (cycle, ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì°¸ì¡°)
        self._validate_graph_topology()
        
        # 2. ë…¸ë“œë³„ ê¸°ë³¸ ê²€ì¦
        for node_id, node in self.graph.nodes.items():
            self._validate_node(node)
        
        # 3. Weight tile ë°°ì¹˜ ê²€ì¦
        self._validate_weight_placement()
        
        # 4. Tiling completeness ê²€ì¦ (tileë“¤ì´ ì™„ì „íˆ ì»¤ë²„í•˜ëŠ”ì§€)
        self._validate_tiling_completeness()
        
        # 5. Shape propagation ê²€ì¦ (input + weight â†’ output)
        self._validate_shape_propagation()
        
        # 6. Areaë³„ reduction dimension íŒ¨í‚¹ ê²€ì¦
        self._validate_area_packing()
        
        # 7. Graph preprocessing ê²°ê³¼ ê²€ì¦ (í™•ì¥ëœ ê·¸ë˜í”„)
        self._validate_graph_preprocessing()
        
        # 8. ê²°ê³¼ ì¶œë ¥
        self._print_results()
        
        return len(self.errors) == 0
    
    def _validate_node(self, node: ComputeNode):
        """ê°œë³„ ë…¸ë“œ ê²€ì¦"""
        
        # Conv ë…¸ë“œ ì¤‘ eFlashë§Œ ê²€ì¦ (NPU ë…¸ë“œëŠ” ì œì™¸)
        if node.node_type not in ["conv"]:
            return
        if node.device_type != "eflash":
            return
        
        # 1. Weight tile ì¡´ì¬ í™•ì¸
        if not node.weight_tiles:
            self.errors.append(f"[{node.node_id}] No weight tiles specified")
            return
        
        # 2. Input shapeì™€ weight reduction dim ê²€ì¦
        self._validate_weight_shape(node)
    
    def _validate_weight_shape(self, node: ComputeNode):
        """
        Weight shape ê²€ì¦ (im2col ê³ ë ¤)
        
        Conv: reduction_dim = kernel_h Ã— kernel_w Ã— input_channels
        """
        # Kernel size ê°€ì ¸ì˜¤ê¸° ('kernel' ë˜ëŠ” 'kernel_size')
        kernel_size = node.metadata.get('kernel') or node.metadata.get('kernel_size')
        if kernel_size is None:
            self.warnings.append(f"[{node.node_id}] No kernel info in metadata")
            return
        
        # Kernel size íŒŒì‹±
        if isinstance(kernel_size, str):
            kernel_str = kernel_size
            if 'x' in kernel_str:
                k_h, k_w = map(int, kernel_str.split('x'))
            else:
                k_h = k_w = int(kernel_str[0])
        elif isinstance(kernel_size, (list, tuple)):
            k_h, k_w = kernel_size
        else:
            # intì¼ ê²½ìš°
            k_h = k_w = kernel_size
        
        # Input channels (CHW format: Channels, Height, Width)
        if len(node.input_shape) == 3:
            input_channels = node.input_shape[0]  # CHW: ChannelsëŠ” ì²« ë²ˆì§¸
        else:
            self.errors.append(f"[{node.node_id}] Invalid input shape: {node.input_shape}")
            return
        
        # ì˜ˆìƒ reduction dim
        expected_reduction_dim = k_h * k_w * input_channels
        
        # Output channels (CHW format: Channels, Height, Width)
        if len(node.output_shape) == 3:
            output_channels = node.output_shape[0]  # CHW: ChannelsëŠ” ì²« ë²ˆì§¸
        else:
            self.errors.append(f"[{node.node_id}] Invalid output shape: {node.output_shape}")
            return
        
        # Weight tile shape ê²€ì¦
        for tile in node.weight_tiles:
            # tileì€ WeightTile ê°ì²´ ë˜ëŠ” stringì¼ ìˆ˜ ìˆìŒ
            if isinstance(tile, str):
                tile_id = tile
                tile_shape = self._get_weight_tile_shape(tile_id, node.array_id)
            else:
                # WeightTile ê°ì²´
                tile_id = tile.weight_id
                tile_shape = tile.get_shape()
            
            if tile_shape is None:
                self.errors.append(f"[{node.node_id}] Weight tile '{tile_id}' not found")
                continue
            
            tile_output_dim, tile_reduction_dim = tile_shape
            
            # Reduction dim ê²€ì¦ (tilingëœ ê²½ìš° ë¶€ë¶„ì ì¼ ìˆ˜ ìˆìŒ)
            # tile_reduction_dimì€ expected_reduction_dim ì´í•˜ì—¬ì•¼ í•¨
            if tile_reduction_dim > expected_reduction_dim:
                self.errors.append(
                    f"[{node.node_id}] Weight tile '{tile_id}' reduction dim too large: "
                    f"expected <= {expected_reduction_dim}, got {tile_reduction_dim}"
                )
            
            # Output dim ê²€ì¦ (tilingëœ ê²½ìš° ë¶€ë¶„ì ì¼ ìˆ˜ ìˆìŒ)
            # tile_output_dimì€ output_channels ì´í•˜ì—¬ì•¼ í•¨
            if tile_output_dim > output_channels:
                self.errors.append(
                    f"[{node.node_id}] Weight tile '{tile_id}' output dim too large: "
                    f"expected <= {output_channels}, got {tile_output_dim}"
                )
    
    def _get_weight_tile_shape(self, tile_id: str, array_id: int) -> Tuple[int, int]:
        """
        Weight tileì˜ shape ì¡°íšŒ
        
        Returns:
            (output_dim, reduction_dim) ë˜ëŠ” None
        """
        array = self.pim.get_array(array_id)
        for area in array.areas:
            for tile in area.tiles:
                if tile.weight_id == tile_id:
                    return tile.get_shape()
        
        # ë‹¤ë¥¸ Arrayì—ì„œë„ ì°¾ì•„ë³´ê¸°
        for arr in self.pim.eflash_arrays:
            for area in arr.areas:
                for tile in area.tiles:
                    if tile.weight_id == tile_id:
                        return tile.get_shape()
        
        return None
    
    def _validate_weight_placement(self):
        """ëª¨ë“  weight tileì´ ë°°ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        for node_id, node in self.graph.nodes.items():
            if node.node_type not in ["conv"]:
                continue
            if node.device_type != "eflash":
                continue
            
            for tile in node.weight_tiles:
                # tileì€ WeightTile ê°ì²´ ë˜ëŠ” stringì¼ ìˆ˜ ìˆìŒ
                if isinstance(tile, str):
                    tile_id = tile
                else:
                    tile_id = tile.weight_id
                
                if not self._is_weight_placed(tile_id):
                    self.errors.append(
                        f"[{node_id}] Weight tile '{tile_id}' is not placed on any array"
                    )
    
    def _is_weight_placed(self, tile_id: str) -> bool:
        """Weight tileì´ ë°°ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        for array in self.pim.eflash_arrays:
            for area in array.areas:
                for tile in area.tiles:
                    if tile.weight_id == tile_id:
                        return True
        return False
    
    def _validate_area_packing(self):
        """Areaë³„ reduction dimension íŒ¨í‚¹ ê²€ì¦"""
        MAX_OUTPUT_DIM = 128
        MAX_REDUCTION_DIM = 1280
        
        total_wasted_reduction = 0
        total_wasted_output = 0
        high_utilization_count = 0
        
        for array_idx, array in enumerate(self.pim.eflash_arrays):
            for area in array.areas:
                if not hasattr(area, 'row_usage') or not area.row_usage:
                    continue  # ë¹ˆ area ê±´ë„ˆë›°ê¸°
                
                # ê° row ë²”ìœ„ ê²€ì¦
                for (start_row, end_row), used_reduction in area.row_usage.items():
                    row_size = end_row - start_row
                    
                    # Output dimension ì´ˆê³¼ ê²€ì¦
                    if end_row > MAX_OUTPUT_DIM:
                        self.errors.append(
                            f"[Array{array_idx}.Area{area.area_id}] Row range ({start_row}-{end_row}) "
                            f"exceeds MAX_OUTPUT_DIM ({MAX_OUTPUT_DIM})"
                        )
                    
                    # Reduction dimension ì´ˆê³¼ ê²€ì¦
                    if used_reduction > MAX_REDUCTION_DIM:
                        self.errors.append(
                            f"[Array{array_idx}.Area{area.area_id}] Rows {start_row}-{end_row}: "
                            f"Reduction dimension ({used_reduction}) exceeds MAX ({MAX_REDUCTION_DIM})"
                        )
                    
                    # Reduction dimension í™œìš©ë„ ê³„ì‚°
                    reduction_util = (used_reduction / MAX_REDUCTION_DIM) * 100
                    wasted_reduction = MAX_REDUCTION_DIM - used_reduction
                    total_wasted_reduction += wasted_reduction
                    
                    # ë†’ì€ í™œìš©ë„ ì¹´ìš´íŠ¸ (>80%)
                    if reduction_util > 80:
                        high_utilization_count += 1
                    
                    # ë‚®ì€ í™œìš©ë„ ê²½ê³  (<30%)
                    if reduction_util < 30:
                        self.warnings.append(
                            f"[Array{array_idx}.Area{area.area_id}] Rows {start_row}-{end_row}: "
                            f"Low reduction utilization ({reduction_util:.1f}%)"
                        )
                
                # Output dimension í™œìš©ë„ ê³„ì‚°
                max_row_used = max((end for _, end in area.row_usage.keys()), default=0)
                output_util = (max_row_used / MAX_OUTPUT_DIM) * 100
                wasted_output = MAX_OUTPUT_DIM - max_row_used
                total_wasted_output += wasted_output
                
                # ë‚®ì€ output í™œìš©ë„ ê²½ê³  (<50%)
                if max_row_used > 0 and output_util < 50:
                    self.warnings.append(
                        f"[Array{array_idx}.Area{area.area_id}] Low output utilization "
                        f"({output_util:.1f}%, only {max_row_used}/{MAX_OUTPUT_DIM} rows used)"
                    )
        
        # í†µê³„ ì €ì¥ (ì¶œë ¥ì—ì„œ ì‚¬ìš©)
        self.packing_stats = {
            'total_wasted_reduction': total_wasted_reduction,
            'total_wasted_output': total_wasted_output,
            'high_utilization_count': high_utilization_count
        }
    
    def _validate_graph_topology(self):
        """Graph topology ê²€ì¦: cycle, ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì°¸ì¡° ë“±"""
        
        # 1. ëª¨ë“  input_nodesê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        for node_id, node in self.graph.nodes.items():
            for inp_id in node.input_nodes:
                if inp_id not in self.graph.nodes:
                    self.errors.append(
                        f"[{node_id}] References non-existent input node '{inp_id}'"
                    )
        
        # 2. Cycle ê²€ì¶œ (DFS)
        visited = set()
        rec_stack = set()
        cycle_path = []
        
        def has_cycle_dfs(node_id, path):
            visited.add(node_id)
            rec_stack.add(node_id)
            path.append(node_id)
            
            if node_id in self.graph.nodes:
                for inp_id in self.graph.nodes[node_id].input_nodes:
                    if inp_id not in visited:
                        if has_cycle_dfs(inp_id, path):
                            return True
                    elif inp_id in rec_stack:
                        # Cycle ë°œê²¬
                        cycle_start_idx = path.index(inp_id)
                        cycle_nodes = path[cycle_start_idx:] + [inp_id]
                        self.errors.append(
                            f"Cycle detected in graph: {' â†’ '.join(cycle_nodes)}"
                        )
                        return True
            
            path.pop()
            rec_stack.remove(node_id)
            return False
        
        for node_id in self.graph.nodes:
            if node_id not in visited:
                has_cycle_dfs(node_id, [])
    
    def _validate_tiling_completeness(self):
        """Weight tilingì´ ì™„ì „í•œì§€ ê²€ì¦: tileë“¤ì´ ì›ë³¸ weightë¥¼ ì™„ì „íˆ ì»¤ë²„í•˜ëŠ”ì§€"""
        
        for node_id, node in self.graph.nodes.items():
            # Conv ë…¸ë“œì´ê³  eFlashì¸ ê²½ìš°ë§Œ ê²€ì¦
            if node.node_type != "conv" or node.device_type != "eflash":
                continue
            
            if not node.weight_tiles:
                continue
            
            # Metadataì—ì„œ tiling ì •ë³´ ì¶”ì¶œ
            output_ranges = []
            reduction_ranges = []
            
            for tile in node.weight_tiles:
                if isinstance(tile, str):
                    # Stringì¸ ê²½ìš° ì‹¤ì œ tile ê°ì²´ ì°¾ê¸°
                    tile_obj = self._find_weight_tile(tile, node.array_id)
                    if tile_obj is None:
                        continue
                    metadata = tile_obj.metadata
                else:
                    metadata = tile.metadata
                
                if metadata is None:
                    continue
                
                # Output range
                if 'output_start' in metadata and 'output_end' in metadata:
                    output_ranges.append((metadata['output_start'], metadata['output_end']))
                
                # Reduction range
                if 'reduction_start' in metadata and 'reduction_end' in metadata:
                    reduction_ranges.append((metadata['reduction_start'], metadata['reduction_end']))
            
            # Output shapeì—ì„œ expected dimensions ê³„ì‚°
            if len(node.output_shape) >= 1:
                expected_output_channels = node.output_shape[0]
            else:
                continue
            
            # Expected reduction dimension ê³„ì‚°
            kernel_size = node.metadata.get('kernel') or node.metadata.get('kernel_size')
            if kernel_size is None:
                continue
            
            if isinstance(kernel_size, str):
                if 'x' in kernel_size:
                    k_h, k_w = map(int, kernel_size.split('x'))
                else:
                    k_h = k_w = int(kernel_size[0])
            elif isinstance(kernel_size, (list, tuple)):
                k_h, k_w = kernel_size
            else:
                k_h = k_w = kernel_size
            
            if len(node.input_shape) >= 1:
                input_channels = node.input_shape[0]
                expected_reduction_dim = k_h * k_w * input_channels
            else:
                continue
            
            # Output dimension completeness ê²€ì¦
            if output_ranges:
                is_valid, error_msg = self._is_continuous_coverage(
                    output_ranges, 0, expected_output_channels
                )
                if not is_valid:
                    self.errors.append(
                        f"[{node_id}] Output dimension tiling incomplete: {error_msg}"
                    )
            
            # Reduction dimension completeness ê²€ì¦
            if reduction_ranges:
                is_valid, error_msg = self._is_continuous_coverage(
                    reduction_ranges, 0, expected_reduction_dim
                )
                if not is_valid:
                    self.errors.append(
                        f"[{node_id}] Reduction dimension tiling incomplete: {error_msg}"
                    )
    
    def _find_weight_tile(self, tile_id: str, array_id: int):
        """Weight tile ê°ì²´ ì°¾ê¸°"""
        # ì§€ì •ëœ arrayì—ì„œ ë¨¼ì € ì°¾ê¸°
        if array_id is not None and array_id < len(self.pim.eflash_arrays):
            array = self.pim.eflash_arrays[array_id]
            for area in array.areas:
                for tile in area.tiles:
                    if tile.weight_id == tile_id:
                        return tile
        
        # ëª¨ë“  arrayì—ì„œ ì°¾ê¸°
        for array in self.pim.eflash_arrays:
            for area in array.areas:
                for tile in area.tiles:
                    if tile.weight_id == tile_id:
                        return tile
        
        return None
    
    def _validate_shape_propagation(self):
        """Shape propagation ê²€ì¦: input shape + weight â†’ output shape"""
        
        for node_id, node in self.graph.nodes.items():
            if node.node_type == "conv":
                self._validate_conv_shape(node)
            elif node.node_type == "concat":
                self._validate_concat_shape(node)
            elif node.node_type == "add":
                self._validate_add_shape(node)
    
    def _validate_conv_shape(self, node: ComputeNode):
        """Conv ë…¸ë“œì˜ shape ê²€ì¦"""
        
        if len(node.input_shape) != 3 or len(node.output_shape) != 3:
            return  # Shape ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ìŠ¤í‚µ
        
        C_in, H_in, W_in = node.input_shape
        C_out, H_out, W_out = node.output_shape
        
        # Kernel size
        kernel_size = node.metadata.get('kernel') or node.metadata.get('kernel_size')
        if kernel_size is None:
            return
        
        if isinstance(kernel_size, str):
            if 'x' in kernel_size:
                k_h, k_w = map(int, kernel_size.split('x'))
            else:
                k_h = k_w = int(kernel_size[0])
        elif isinstance(kernel_size, (list, tuple)):
            k_h, k_w = kernel_size
        else:
            k_h = k_w = kernel_size
        
        # Stride, padding
        stride = node.metadata.get('stride', 1)
        padding = node.metadata.get('padding', 0)
        
        # Output spatial size ê³„ì‚°
        H_out_calc = self._calculate_conv_output_size(H_in, k_h, stride, padding)
        W_out_calc = self._calculate_conv_output_size(W_in, k_w, stride, padding)
        
        # ê²€ì¦
        if H_out_calc != H_out:
            self.errors.append(
                f"[{node.node_id}] Output height mismatch: "
                f"calculated {H_out_calc}, specified {H_out}"
            )
        
        if W_out_calc != W_out:
            self.errors.append(
                f"[{node.node_id}] Output width mismatch: "
                f"calculated {W_out_calc}, specified {W_out}"
            )
        
        # Weight tileë“¤ì˜ ì´ output channels í™•ì¸ (eFlashì¸ ê²½ìš°)
        if node.device_type == "eflash" and node.weight_tiles:
            total_output_from_tiles = 0
            for tile in node.weight_tiles:
                if isinstance(tile, str):
                    tile_shape = self._get_weight_tile_shape(tile, node.array_id)
                else:
                    tile_shape = tile.get_shape()
                
                if tile_shape:
                    # Output dimensionë³„ë¡œ ê³ ìœ í•œ tileë§Œ ì¹´ìš´íŠ¸
                    tile_metadata = tile.metadata if not isinstance(tile, str) else self._find_weight_tile(tile, node.array_id).metadata
                    if tile_metadata and 'reduction_tile_idx' in tile_metadata and tile_metadata['reduction_tile_idx'] == 0:
                        total_output_from_tiles += tile_shape[0]
            
            if total_output_from_tiles > 0 and total_output_from_tiles != C_out:
                self.warnings.append(
                    f"[{node.node_id}] Total output channels from tiles ({total_output_from_tiles}) "
                    f"!= expected ({C_out})"
                )
    
    def _validate_concat_shape(self, node: ComputeNode):
        """Concat ë…¸ë“œì˜ shape ê²€ì¦"""
        
        if not node.input_nodes or len(node.output_shape) < 1:
            return
        
        # ì…ë ¥ë“¤ì˜ ì±„ë„ ìˆ˜ í•©ê³„ ê³„ì‚°
        expected_output_channels = 0
        for inp_id in node.input_nodes:
            if inp_id in self.graph.nodes:
                inp_node = self.graph.nodes[inp_id]
                if len(inp_node.output_shape) >= 1:
                    expected_output_channels += inp_node.output_shape[0]
        
        actual_output_channels = node.output_shape[0]
        
        if expected_output_channels > 0 and actual_output_channels != expected_output_channels:
            self.errors.append(
                f"[{node.node_id}] Concat output channels mismatch: "
                f"sum of inputs = {expected_output_channels}, specified = {actual_output_channels}"
            )
    
    def _validate_add_shape(self, node: ComputeNode):
        """Add ë…¸ë“œì˜ shape ê²€ì¦"""
        
        if not node.input_nodes:
            return
        
        # ëª¨ë“  ì…ë ¥ì´ ê°™ì€ shapeì„ ê°€ì ¸ì•¼ í•¨
        shapes = []
        for inp_id in node.input_nodes:
            if inp_id in self.graph.nodes:
                shapes.append(tuple(self.graph.nodes[inp_id].output_shape))
        
        if len(shapes) > 1 and len(set(shapes)) > 1:
            self.errors.append(
                f"[{node.node_id}] Add operation requires all inputs to have same shape, "
                f"but got: {shapes}"
            )
        
        # Output shapeë„ ì…ë ¥ê³¼ ë™ì¼í•´ì•¼ í•¨
        if shapes and tuple(node.output_shape) != shapes[0]:
            self.errors.append(
                f"[{node.node_id}] Add output shape {tuple(node.output_shape)} "
                f"doesn't match input shape {shapes[0]}"
            )
    
    def _validate_graph_preprocessing(self):
        """Graph preprocessing ê²°ê³¼ ê²€ì¦: reduce/concat ë…¸ë“œ êµ¬ì¡°"""
        
        for node_id, node in self.graph.nodes.items():
            # Reduce ë…¸ë“œ ê²€ì¦
            if "reduce" in node_id.lower() and "tile" in node_id.lower():
                self._validate_reduce_node(node)
            
            # Tiled concat ë…¸ë“œ ê²€ì¦
            if "concat" in node_id.lower() and "tile" in node_id.lower():
                self._validate_tiled_concat_node(node)
    
    def _validate_reduce_node(self, node: ComputeNode):
        """Reduce ë…¸ë“œ ê²€ì¦: ëª¨ë“  inputì´ ê°™ì€ output tile indexë¥¼ ê°€ì ¸ì•¼ í•¨"""
        
        if not node.input_nodes:
            return
        
        output_tile_indices = set()
        for inp_id in node.input_nodes:
            if inp_id in self.graph.nodes:
                inp_node = self.graph.nodes[inp_id]
                if inp_node.metadata and 'output_tile_idx' in inp_node.metadata:
                    output_tile_indices.add(inp_node.metadata['output_tile_idx'])
        
        if len(output_tile_indices) > 1:
            self.errors.append(
                f"[{node.node_id}] Reduce node has inputs with different output tile indices: {output_tile_indices}"
            )
    
    def _validate_tiled_concat_node(self, node: ComputeNode):
        """Tiled concat ë…¸ë“œ ê²€ì¦: ì…ë ¥ë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ output tile indexë¥¼ ê°€ì ¸ì•¼ í•¨"""
        
        if not node.input_nodes:
            return
        
        output_tile_indices = []
        for inp_id in node.input_nodes:
            if inp_id in self.graph.nodes:
                inp_node = self.graph.nodes[inp_id]
                if inp_node.metadata and 'output_tile_idx' in inp_node.metadata:
                    idx = inp_node.metadata['output_tile_idx']
                    if idx in output_tile_indices:
                        self.errors.append(
                            f"[{node.node_id}] Concat node has duplicate output tile index {idx}"
                        )
                    output_tile_indices.append(idx)
    
    def _print_results(self):
        """ê²€ì¦ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ” GRAPH VALIDATION RESULTS")
        print("=" * 80)
        
        if self.errors:
            print(f"\nâŒ {len(self.errors)} Error(s) found:")
            for error in self.errors:
                print(f"  â€¢ {error}")
        
        if self.warnings:
            print(f"\nâš ï¸  {len(self.warnings)} Warning(s):")
            for warning in self.warnings:
                print(f"  â€¢ {warning}")
        
        if not self.errors and not self.warnings:
            print("\nâœ… All validations passed!")
        
        # Weight Packing í†µê³„
        if hasattr(self, 'packing_stats'):
            stats = self.packing_stats
            print(f"\nğŸ“Š Weight Packing Statistics:")
            print(f"  â€¢ High utilization row ranges (>80%): {stats['high_utilization_count']}")
            if stats['total_wasted_reduction'] > 0:
                print(f"  â€¢ Total wasted reduction dimension: {stats['total_wasted_reduction']:.0f} "
                      f"(~{stats['total_wasted_reduction']/1280:.1f} full columns)")
            if stats['total_wasted_output'] > 0:
                print(f"  â€¢ Total wasted output dimension: {stats['total_wasted_output']:.0f} "
                      f"(~{stats['total_wasted_output']/128:.1f} full areas)")
        
        print("=" * 80)
